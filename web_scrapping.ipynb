{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e55bd4-4f53-4b77-a9a5-aff1d20c939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4249dbec-495a-4159-af42-b25bfb5c248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://books.toscrape.com/catalogue/page-1.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c767a37-6ca7-416a-a1cb-1f9670768400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic\n",
      "Tipping the Velvet\n",
      "Soumission\n",
      "Sharp Objects\n",
      "Sapiens: A Brief History of Humankind\n",
      "The Requiem Red\n",
      "The Dirty Little Secrets of Getting Your Dream Job\n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\n",
      "The Black Maria\n",
      "Starving Hearts (Triangular Trade Trilogy, #1)\n",
      "Shakespeare's Sonnets\n",
      "Set Me Free\n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\n",
      "Rip it Up and Start Again\n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\n",
      "Olio\n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849\n",
      "Libertarianism for Beginners\n",
      "It's Only the Himalayas\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "\n",
    "for book in books:\n",
    "    title = book.h3.a[\"title\"]\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "addb1850-d388-4c92-91c0-16fbaefdc8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Quotes saved to quotes.csv\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import csv  \n",
    "\n",
    "url = \"https://quotes.toscrape.com\" \n",
    "response = requests.get(url) \n",
    "soup = BeautifulSoup(response.text, \"html.parser\") \n",
    "\n",
    "# Extract quotes and authors\n",
    "quotes = [q.text for q in soup.find_all(\"span\", class_=\"text\")] \n",
    "authors = [a.text for a in soup.find_all(\"small\", class_=\"author\")] \n",
    "\n",
    "# Combine into list of tuples (for CSV)\n",
    "data = [(\"quote\", \"author\")]  # header row\n",
    "for q, a in zip(quotes, authors): \n",
    "    data.append((q, a))\n",
    "\n",
    "# Save to CSV\n",
    "with open(\"quotes.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f: \n",
    "    writer = csv.writer(f) \n",
    "    writer.writerows(data) \n",
    "\n",
    "print(\"✅ Quotes saved to quotes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0893d82a-3be1-47b1-b865-876ccd2e93ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scraping completed! Data saved to books.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "books_data = [(\"Title\", \"Price\", \"Availability\", \"Star Rating\")]  # header row\n",
    "\n",
    "# Loop through all 50 pages\n",
    "for page in range(1, 51):\n",
    "    url = base_url.format(page)\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"⚠️ Failed to fetch page {page}\")\n",
    "        continue\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    \n",
    "    for book in books:\n",
    "        title = book.h3.a[\"title\"]\n",
    "        price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
    "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "        rating = book.find(\"p\", class_=\"star-rating\")[\"class\"][1]  # second class = One/Two/...\n",
    "        \n",
    "        books_data.append((title, price, availability, rating))\n",
    "\n",
    "# Save to CSV\n",
    "with open(\"books.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(books_data)\n",
    "\n",
    "print(\"✅ Scraping completed! Data saved to books.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb529d7a-c62f-4995-a37c-f53044c9103a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
